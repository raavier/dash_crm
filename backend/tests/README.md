# Dashboard CRM API - Tests

Suite de testes automatizados para validar queries SQL, lÃ³gica de negÃ³cio e endpoints REST.

## ğŸ§ª Estrutura dos Testes

```
tests/
â”œâ”€â”€ conftest.py           # Fixtures compartilhadas (filtros 2025, etc.)
â”œâ”€â”€ test_queries.py       # Testes de queries SQL diretas
â”œâ”€â”€ test_service.py       # Testes da camada de serviÃ§o
â”œâ”€â”€ test_api.py           # Testes dos endpoints REST
â””â”€â”€ README.md            # Esta documentaÃ§Ã£o
```

## ğŸ¯ Tipos de Testes

### 1. Testes de Queries (test_queries.py)

Testa queries SQL diretamente no Databricks para validar:
- âœ… Total de verificaÃ§Ãµes em 2025 = **316414**
- âœ… Contagem de controles nÃ£o conformes
- âœ… DistribuiÃ§Ã£o de prioridades de aÃ§Ãµes
- âœ… JOINs com usuÃ¡rios e localizaÃ§Ãµes

**Exemplo:**
```python
def test_total_verifications_2025(self, filters_2025, expected_verifications_2025):
    """Valida que o total de verificaÃ§Ãµes em 2025 = 316414"""
```

### 2. Testes de ServiÃ§o (test_service.py)

Testa a camada de negÃ³cio (services/dashboard_service.py):
- âœ… CÃ¡lculo correto de percentuais
- âœ… TransformaÃ§Ã£o de dados (DB â†’ Pydantic models)
- âœ… PaginaÃ§Ã£o
- âœ… AplicaÃ§Ã£o de filtros

**Exemplo:**
```python
def test_get_metrics_2025(self, filters_2025, expected_verifications_2025):
    """Valida que get_metrics retorna estrutura correta com total = 316414"""
```

### 3. Testes de API (test_api.py)

Testa os endpoints REST usando FastAPI TestClient:
- âœ… Status codes corretos (200, 422, etc.)
- âœ… Estrutura de resposta JSON
- âœ… ValidaÃ§Ã£o de parÃ¢metros
- âœ… CORS e headers

**Exemplo:**
```python
def test_metrics_endpoint_2025(self, client, expected_verifications_2025):
    """Valida POST /api/metrics retorna 200 e dados corretos"""
```

## ğŸš€ Executando os Testes

### PrÃ©-requisitos

1. **Ambiente virtual ativado**:
   ```bash
   cd backend
   venv\Scripts\activate  # Windows
   # source venv/bin/activate  # Linux/Mac
   ```

2. **DependÃªncias instaladas**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Arquivo .env configurado** com credenciais Databricks:
   ```env
   DATABRICKS_HOST=adb-116288240407984.4.azuredatabricks.net
   DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/YOUR_WAREHOUSE_ID
   DATABRICKS_TOKEN=YOUR_TOKEN_HERE
   ```

### Executar Todos os Testes

```bash
pytest
```

### Executar Testes EspecÃ­ficos

```bash
# Apenas testes de queries
pytest tests/test_queries.py

# Apenas testes de serviÃ§o
pytest tests/test_service.py

# Apenas testes de API
pytest tests/test_api.py

# Teste especÃ­fico (total de verificaÃ§Ãµes 2025)
pytest tests/test_queries.py::TestVerificationsQuery::test_total_verifications_2025

# Testes com output detalhado
pytest -v -s
```

### Executar com Marcadores

```bash
# Apenas testes rÃ¡pidos (sem testes marcados como 'slow')
pytest -m "not slow"

# Apenas testes de integraÃ§Ã£o
pytest -m integration

# Apenas testes unitÃ¡rios
pytest -m unit
```

## ğŸ“Š Exemplo de SaÃ­da

```
============================= test session starts ==============================
collected 15 items

tests/test_queries.py::TestVerificationsQuery::test_total_verifications_2025 PASSED
âœ“ Total verifications in 2025: 316414

tests/test_service.py::TestMetricsService::test_get_metrics_2025 PASSED
âœ“ Metrics for 2025:
  Verifications: 316414 total, 63705 non-compliant (20.13%)
  Controls: 772899 total, 70015 non-compliant (9.06%)

tests/test_api.py::TestMetricsEndpoint::test_metrics_endpoint_2025 PASSED
âœ“ POST /api/metrics (2025):
  Verifications: 316414 total, 20.13% non-compliant

============================== 15 passed in 12.34s ==============================
```

## âœ… ValidaÃ§Ãµes Principais

### Total de VerificaÃ§Ãµes 2025

O teste mais importante valida que:
```python
assert result.verifications.total == 316414
```

Isso garante que:
- A query estÃ¡ corretamente filtrando por data
- O JOIN com outras tabelas nÃ£o duplica registros
- A contagem DISTINCT estÃ¡ funcionando

### Percentuais de NÃ£o Conformidade

Valida que os cÃ¡lculos estÃ£o corretos:
```python
percentage = round((nonCompliant * 100.0) / total, 2)
assert result.percentage == percentage
```

### Estrutura de Dados

Valida que os modelos Pydantic correspondem aos dados:
```python
assert isinstance(result, MetricsData)
assert result.verifications.total > 0
assert 0 <= result.verifications.percentage <= 100
```

## ğŸ› Troubleshooting

### Erro de ConexÃ£o com Databricks

```
Error connecting to Databricks: ...
```

**SoluÃ§Ã£o:**
- Verifique se o arquivo `.env` estÃ¡ configurado corretamente
- Teste a conexÃ£o usando `docs/main.ipynb`
- Verifique se o token nÃ£o expirou

### Teste Falhou: Total Diferente de 316414

```
AssertionError: Expected 316414 verifications in 2025, but got XXXXX
```

**PossÃ­veis causas:**
1. **Dados foram atualizados**: O valor 316414 era vÃ¡lido em uma data especÃ­fica. Se os dados mudaram, atualize o valor esperado em `conftest.py`:
   ```python
   @pytest.fixture
   def expected_verifications_2025():
       return 316414  # Atualizar para novo valor
   ```

2. **Filtros incorretos**: Verifique se a query estÃ¡ usando o intervalo de datas correto (2025-01-01 a 2025-12-31)

3. **JOINs duplicando registros**: Verifique se estÃ¡ usando `COUNT(DISTINCT v.ID)`

### Testes Lentos

Se os testes estiverem demorando muito:

```bash
# Executar apenas testes rÃ¡pidos
pytest -m "not slow"

# Limitar nÃºmero de testes
pytest tests/test_api.py -k "health"
```

## ğŸ“ Adicionando Novos Testes

### PadrÃ£o para Novos Testes

```python
def test_my_new_feature(self, filters_2025):
    """
    DescriÃ§Ã£o clara do que o teste valida.

    Validates:
    - Item 1
    - Item 2
    """
    # Arrange
    expected_value = 123

    # Act
    result = dashboard_service.get_something(filters_2025)

    # Assert
    assert result == expected_value, f"Expected {expected_value}, got {result}"

    # Print (opcional, para debug)
    print(f"âœ“ Test passed: {result}")
```

### Boas PrÃ¡ticas

1. **Nome descritivo**: `test_what_it_validates_when_condition`
2. **Docstring clara**: Explique o que estÃ¡ sendo validado
3. **Assertions especÃ­ficas**: Use mensagens de erro descritivas
4. **Fixtures reutilizÃ¡veis**: Use fixtures do `conftest.py`
5. **Prints informativos**: Ajudam no debug e documentaÃ§Ã£o visual

## ğŸ”— ReferÃªncias

- [Pytest Documentation](https://docs.pytest.org/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [DATABASE_SCHEMA.md](../../docs/DATABASE_SCHEMA.md) - Queries SQL
- [dashboard_service.py](../services/dashboard_service.py) - ImplementaÃ§Ã£o

## ğŸ“ Suporte

Se algum teste falhar inesperadamente:
1. Verifique se o backend estÃ¡ rodando: `python main.py`
2. Teste manualmente no Swagger: http://localhost:8000/docs
3. Verifique os logs do backend para mais detalhes
4. Compare com queries no notebook: `docs/main.ipynb`
